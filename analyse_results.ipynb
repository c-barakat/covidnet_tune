{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approved-mauritius",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import simplejson\n",
    "\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liable-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(os.getcwd())\n",
    "from data import process_image_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mechanical-musician",
   "metadata": {},
   "source": [
    "# Read and Clean Ray Tune Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prepared-sessions",
   "metadata": {},
   "outputs": [],
   "source": [
    "working_dir = os.getcwd()\n",
    "trial_dir = os.path.join(working_dir, \"trials\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "passing-retail",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = \"ahb\"\n",
    "# scheduler = \"hpb\"\n",
    "scheduler = \"pbt\"\n",
    "# scheduler = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "communist-greek",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler_dir = os.path.join(trial_dir, f\"{scheduler}_Train_COVID_Net\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "floppy-invitation",
   "metadata": {},
   "outputs": [],
   "source": [
    "stored_data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certain-metallic",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for trial in sorted(glob.glob(os.path.join(scheduler_dir, \"*\", \"result.json\"))):\n",
    "    losses = [simplejson.loads(line)[\"Losses\"] for line in open(trial)]\n",
    "    accuracies = [simplejson.loads(line)[\"Accuracies\"] for line in open(trial)]\n",
    "    learning_rates = [\n",
    "        simplejson.loads(line)[\"config\"][\"learning_rate\"] for line in open(trial)\n",
    "    ]\n",
    "    class_weights = [\n",
    "        [simplejson.loads(line)[\"config\"][\"class_weight_1\"] for line in open(trial)][\n",
    "            -1\n",
    "        ],\n",
    "        [simplejson.loads(line)[\"config\"][\"class_weight_2\"] for line in open(trial)][\n",
    "            -1\n",
    "        ],\n",
    "        [simplejson.loads(line)[\"config\"][\"class_weight_3\"] for line in open(trial)][\n",
    "            -1\n",
    "        ],\n",
    "    ]\n",
    "    covid_percent = [\n",
    "        simplejson.loads(line)[\"config\"][\"covid_percent\"] for line in open(trial)\n",
    "    ][-1]\n",
    "\n",
    "    if len(set(learning_rates)) < 2:\n",
    "        learning_rates = learning_rates[-1]\n",
    "\n",
    "    time_total_m = [simplejson.loads(line)[\"time_total_s\"] for line in open(trial)][\n",
    "        -1\n",
    "    ] / 60\n",
    "\n",
    "    num_iterations = [\n",
    "        simplejson.loads(line)[\"training_iteration\"] for line in open(trial)\n",
    "    ][-1]\n",
    "\n",
    "    stored_data[i] = {\n",
    "        \"losses\": losses,\n",
    "        \"accuracies\": accuracies,\n",
    "        \"learning_rates\": learning_rates,\n",
    "        \"class_weights\": class_weights,\n",
    "        \"covid_percent\": covid_percent,\n",
    "        \"time_total_m\": time_total_m,\n",
    "        \"num_iterations\": num_iterations,\n",
    "    }\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "removed-sixth",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{scheduler}_results.json\", \"w\") as f:\n",
    "    simplejson.dump(stored_data, f, allow_nan=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "chronic-timeline",
   "metadata": {},
   "source": [
    "# Best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dated-chain",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-editing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = \"ahb\"\n",
    "# scheduler = \"hpb\"\n",
    "scheduler = \"pbt\"\n",
    "# scheduler = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "threaded-salvation",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{scheduler}_results.json\", \"r\") as f:\n",
    "    stored_data = simplejson.load(f)\n",
    "    df = pd.DataFrame(columns=stored_data[\"0\"].keys())\n",
    "    for trial in stored_data:\n",
    "        df.at[trial, \"covid_percent\"] = stored_data[trial][\"covid_percent\"]\n",
    "        df.at[trial, \"time_total_m\"] = stored_data[trial][\"time_total_m\"]\n",
    "        df.at[trial, \"num_iterations\"] = stored_data[trial][\"num_iterations\"]\n",
    "        df.at[trial, \"class_weights\"] = stored_data[trial][\"class_weights\"]\n",
    "        #         takes into consideration different learning rates in the case of PBT perturbations\n",
    "        df.at[trial, \"learning_rates\"] = pd.Series(\n",
    "            stored_data[trial][\"learning_rates\"]\n",
    "        ).unique()\n",
    "        #         takes the final accuracy and loss values\n",
    "        df.at[trial, \"losses\"] = pd.Series(stored_data[trial][\"losses\"]).to_list()[-1]\n",
    "        df.at[trial, \"accuracies\"] = pd.Series(\n",
    "            stored_data[trial][\"accuracies\"]\n",
    "        ).to_list()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[\n",
    "    ((df.accuracies > 0.5) & (df.num_iterations == 24))\n",
    "    | ((df.losses == df.losses.min()) | (df.accuracies == df.accuracies.max()))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-faith",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"scheduler\"] = scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "atmospheric-savage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-london",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df = out_df.append(df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prerequisite-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_df.to_csv(\"training_joblist.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hourly-honolulu",
   "metadata": {},
   "source": [
    "# Trial Durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "monthly-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scheduler = \"ahb\"\n",
    "# scheduler = \"hpb\"\n",
    "# scheduler = \"pbt\"\n",
    "scheduler = \"None\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dying-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{scheduler}_results.json\", \"r\") as f:\n",
    "    stored_data = simplejson.load(f)\n",
    "    times = []\n",
    "    for trial in stored_data:\n",
    "        times += [stored_data[trial][\"time_total_m\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advisory-cotton",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(times)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-bahamas",
   "metadata": {},
   "source": [
    "# Prediction Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "american-committee",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.DataFrame(columns=[\"pred\",\"time\",\"true\", \"true_mapped\", \"scheduler\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recognized-texas",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = [\"trial_fifo\", \"trial_hpb\", \"trial_ahb\", \"trial_pbt\"]\n",
    "scheduler = [\"FIFO\", \"HyperBand\", \"Asynchronous HyperBand\", \"PBT\"]\n",
    "classes = [\"Healthy\", \"Pneumonia\", \"Covid-19\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-today",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    trial_pred = pd.read_csv(f\"results/{trial[i]}_predictions.csv\")\n",
    "    trial_pred[\"scheduler\"] = scheduler[i]\n",
    "    predictions = predictions.append(trial_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-reminder",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_crosstab(predictions, scheduler):\n",
    "    return pd.crosstab(\n",
    "        predictions[predictions.scheduler == scheduler][\"true_mapped\"],\n",
    "        predictions[predictions.scheduler == scheduler][\"pred\"],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-subscriber",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(15, 15))\n",
    "sns.heatmap(\n",
    "    create_crosstab(predictions, \"FIFO\").apply(lambda x: 100 * x / x.sum(), axis=1),\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 18},\n",
    "    ax=ax[0, 0],\n",
    "    fmt=\".3f\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    cbar=False,\n",
    ")\n",
    "ax[0, 0].set_title(\"FIFO\", fontsize=20)\n",
    "ax[0, 0].set_xlabel(\"(a)\", size=20)\n",
    "ax[0, 0].set_ylabel(\"\", size=20)\n",
    "ax[0, 0].set_xticklabels(classes, size=18)\n",
    "ax[0, 0].set_yticklabels(classes, size=18, va=\"center\")\n",
    "\n",
    "sns.heatmap(\n",
    "    create_crosstab(predictions, \"HyperBand\").apply(\n",
    "        lambda x: 100 * x / x.sum(), axis=1\n",
    "    ),\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 18},\n",
    "    ax=ax[0, 1],\n",
    "    fmt=\".3f\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    cbar=False,\n",
    ")\n",
    "ax[0, 1].set_title(\"HyperBand\", fontsize=20)\n",
    "ax[0, 1].set_xlabel(\"(b)\", size=20)\n",
    "ax[0, 1].set_ylabel(\"\", size=20)\n",
    "ax[0, 1].set_xticklabels(classes, size=18)\n",
    "ax[0, 1].set_yticklabels(classes, size=18, va=\"center\")\n",
    "\n",
    "sns.heatmap(\n",
    "    create_crosstab(predictions, \"Asynchronous HyperBand\").apply(\n",
    "        lambda x: 100 * x / x.sum(), axis=1\n",
    "    ),\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 18},\n",
    "    ax=ax[1, 0],\n",
    "    fmt=\".3f\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    cbar=False,\n",
    ")\n",
    "ax[1, 0].set_title(\"Asynchronous HyperBand\", fontsize=20)\n",
    "ax[1, 0].set_xlabel(\"(c)\", size=20)\n",
    "ax[1, 0].set_ylabel(\"\", size=20)\n",
    "ax[1, 0].set_xticklabels(classes, size=18)\n",
    "ax[1, 0].set_yticklabels(classes, size=18, va=\"center\")\n",
    "\n",
    "sns.heatmap(\n",
    "    create_crosstab(predictions, \"PBT\").apply(lambda x: 100 * x / x.sum(), axis=1),\n",
    "    cmap=\"Blues\",\n",
    "    annot=True,\n",
    "    annot_kws={\"fontsize\": 18},\n",
    "    ax=ax[1, 1],\n",
    "    fmt=\".3f\",\n",
    "    vmin=0,\n",
    "    vmax=100,\n",
    "    cbar=False,\n",
    ")\n",
    "ax[1, 1].set_title(\"PBT\", fontsize=20)\n",
    "ax[1, 1].set_xlabel(\"(d)\", size=20)\n",
    "ax[1, 1].set_ylabel(\"\", size=20)\n",
    "ax[1, 1].set_xticklabels(classes, size=18)\n",
    "ax[1, 1].set_yticklabels(classes, size=18, va=\"center\")\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "plt.savefig(\"figures/heatmaps_all.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adolescent-venice",
   "metadata": {},
   "source": [
    "# Run Speeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "empty-louisiana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adequate-saying",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes = pd.DataFrame(columns=[\"num\", \"runtime\"])\n",
    "for i in range(6):\n",
    "    file = \"training_run_size_\" + str(2**i) + \".csv\"\n",
    "    runtimes.loc[i, \"num\"] = 2 ** i\n",
    "    runtimes.loc[i, \"runtime\"] = pd.read_csv(file).time.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verified-blogger",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes[\"runtime_m\"] = runtimes.runtime.apply(lambda x: int(x/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confident-search",
   "metadata": {},
   "outputs": [],
   "source": [
    "runtimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-parking",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15, 10))\n",
    "# Linear scale\n",
    "ax[0].plot(runtimes.num, runtimes.runtime_m)\n",
    "ax[0].set_xticks([num for num in runtimes.num])\n",
    "ax[0].tick_params(axis='both', labelsize=16)\n",
    "ax[0].set_xlabel(\"Number of GPU Nodes\", size=20)\n",
    "ax[0].set_ylabel(\"Runtime (in minutes)\", size=20)\n",
    "ax[0].set_title('(a)', size=20)\n",
    "ax[0].grid()\n",
    "# log (base 2) scale\n",
    "ax[1].plot(runtimes.num, runtimes.runtime_m)\n",
    "ax[1].set_xticks([num for num in runtimes.num])\n",
    "ax[1].set_xscale(\"log\", basex=2)\n",
    "ax[1].tick_params(axis='both', labelsize=16)\n",
    "ax[1].set_xlabel(\"Number of GPU Nodes\", size=20)\n",
    "ax[1].set_ylabel(\"Runtime (in minutes)\", size=20)\n",
    "ax[1].set_title('(b)', size=20)\n",
    "ax[1].grid()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# plt.savefig(\"figures/GPU_speedup_both.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hidden-argument",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(15, 5))\n",
    "ax.plot(runtimes.num, runtimes.runtime_m)\n",
    "ax.set_xticks([num for num in runtimes.num])\n",
    "ax.tick_params(axis='both', labelsize=16)\n",
    "ax.set_xlabel(\"Number of GPU Nodes\", size=20)\n",
    "ax.set_ylabel(\"Runtime (in minutes)\", size=20)\n",
    "ax.grid()\n",
    "plt.show()\n",
    "# plt.tight_layout()\n",
    "# plt.savefig(\"figures/GPU_speedup.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nuclear-senegal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "covid_kernel",
   "language": "python",
   "name": "covid_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
